{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import json\n",
    "import spacy\n",
    "import random\n",
    "import logging\n",
    "import argparse\n",
    "import itertools\n",
    "import numpy as np\n",
    "from scorer import *\n",
    "import _pickle as cPickle\n",
    "\n",
    "for pack in os.listdir(\"src\"):\n",
    "    sys.path.append(os.path.join(\"src\", pack))\n",
    "\n",
    "sys.path.append(\"/src/shared/\")\n",
    "\n",
    "out_dir = \"model/\"\n",
    "config_path = \"train_config.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "logging.basicConfig(filename=os.path.join(out_dir, \"train_log.txt\"),\n",
    "                    level=logging.DEBUG, filemode='w')\n",
    "\n",
    "# Load json config file\n",
    "with open(config_path, 'r') as js_file:\n",
    "    config_dict = json.load(js_file)\n",
    "\n",
    "with open(os.path.join(out_dir,'train_config.json'), \"w\") as js_file:\n",
    "    json.dump(config_dict, js_file, indent=4, sort_keys=True)\n",
    "\n",
    "random.seed(config_dict[\"random_seed\"])\n",
    "np.random.seed(config_dict[\"random_seed\"])\n",
    "\n",
    "if config_dict[\"gpu_num\"] != -1:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(config_dict[\"gpu_num\"])\n",
    "    use_cuda = True\n",
    "else:\n",
    "    use_cuda = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with CUDA\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "use_cuda = use_cuda and torch.cuda.is_available()\n",
    "\n",
    "import torch.nn as nn\n",
    "from classes import *\n",
    "from eval_utils import *\n",
    "from model_utils import *\n",
    "from model_factory import *\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from spacy.lang.en import English\n",
    "\n",
    "\n",
    "torch.manual_seed(config_dict[\"seed\"])\n",
    "if use_cuda:\n",
    "    torch.cuda.manual_seed(config_dict[\"seed\"])\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    print('Training with CUDA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_set, dev_set, clusterer):\n",
    "    '''\n",
    "    Initializes models, optimizers and loss functions, then, it runs the training procedure that\n",
    "    alternates between entity and event training and clustering on the train set.\n",
    "    After each epoch, it runs the inference procedure on the dev set and calculates\n",
    "    the B-cubed measure and use it to tune the model and its hyper-parameters.\n",
    "    Saves the entity and event models that achieved the best B-cubed scores on the dev set.\n",
    "    :param train_set: a Corpus object, representing the train set.\n",
    "    :param dev_set: a Corpus object, representing the dev set.\n",
    "    '''\n",
    "    device = torch.device(\"cuda:0\" if args.use_cuda else \"cpu\")\n",
    "\n",
    "    doc_to_entity_mentions = load_entity_wd_clusters(config_dict)  # loads predicted WD entity coref chains from external tool\n",
    "\n",
    "    print('Create new models...')\n",
    "    logging.info('Create new models...')\n",
    "    factory_load_embeddings(config_dict)  # loading pre-trained embeddings before creating new models\n",
    "    cd_event_model = create_model(config_dict)\n",
    "    cd_entity_model = create_model(config_dict)\n",
    "\n",
    "    cd_event_model = cd_event_model.to(device)\n",
    "    cd_entity_model = cd_entity_model.to(device)\n",
    "\n",
    "    cd_event_optimizer = create_optimizer(config_dict, cd_event_model)\n",
    "    cd_entity_optimizer = create_optimizer(config_dict, cd_entity_model)\n",
    "\n",
    "    cd_event_loss = create_loss(config_dict)\n",
    "    cd_entity_loss = create_loss(config_dict)\n",
    "\n",
    "    topics = train_set.topics  # Use the gold sub-topics\n",
    "\n",
    "    topics_num = len(topics.keys())\n",
    "    event_best_dev_f1 = 0\n",
    "    entity_best_dev_f1 = 0\n",
    "    best_event_epoch = 0\n",
    "    best_entity_epoch = 0\n",
    "\n",
    "    patient_counter = 0\n",
    "\n",
    "    orig_event_th = config_dict[\"event_merge_threshold\"]\n",
    "    orig_entity_th = config_dict[\"entity_merge_threshold\"]\n",
    "    for epoch in range(1, config_dict[\"epochs\"]):\n",
    "        logging.info('Epoch {}:'.format(str(epoch)))\n",
    "        print('Epoch {}:'.format(str(epoch)))\n",
    "        topics_counter = 0\n",
    "        topics_keys = list(topics.keys())\n",
    "        random.shuffle(topics_keys)\n",
    "        for topic_id in topics_keys:\n",
    "            topics_counter += 1\n",
    "            topic = topics[topic_id]\n",
    "\n",
    "            logging.info('=========================================================================')\n",
    "            logging.info('Topic {}:'.format(topic_id))\n",
    "            print('Topic {}:'.format(topic_id))\n",
    "\n",
    "            # init event and entity clusters\n",
    "            event_mentions, entity_mentions = topic_to_mention_list(topic, is_gold=True)\n",
    "\n",
    "            if config_dict[\"train_init_wd_entity_with_gold\"]:\n",
    "                # initialize entity clusters with gold within document entity coreference chains\n",
    "                wd_entity_clusters = create_gold_wd_clusters_organized_by_doc(entity_mentions, is_event=False)\n",
    "            else:\n",
    "                # initialize entity clusters with within document entity coreference system output\n",
    "                wd_entity_clusters = init_entity_wd_clusters(entity_mentions, doc_to_entity_mentions)\n",
    "\n",
    "            entity_clusters = []\n",
    "            for doc_id, clusters in wd_entity_clusters.items():\n",
    "                entity_clusters.extend(clusters)\n",
    "\n",
    "            event_clusters = init_cd(event_mentions, is_event=True)\n",
    "\n",
    "            # initialize cluster representation\n",
    "            update_lexical_vectors(entity_clusters, cd_entity_model, device,\n",
    "                                   is_event=False, requires_grad=False)\n",
    "            update_lexical_vectors(event_clusters, cd_event_model, device,\n",
    "                                   is_event=True, requires_grad=False)\n",
    "\n",
    "            entity_th = config_dict[\"entity_merge_threshold\"]\n",
    "            event_th = config_dict[\"event_merge_threshold\"]\n",
    "\n",
    "            for i in range(1,config_dict[\"merge_iters\"]+1):\n",
    "                print('Iteration number {}'.format(i))\n",
    "                logging.info('Iteration number {}'.format(i))\n",
    "\n",
    "\n",
    "                # Entities\n",
    "                print('Train entity model and merge entity clusters...')\n",
    "                logging.info('Train entity model and merge entity clusters...')\n",
    "                train_and_merge(clusterer, clusters=entity_clusters, other_clusters=event_clusters,\n",
    "                                model=cd_entity_model, optimizer=cd_entity_optimizer,\n",
    "                                loss=cd_entity_loss,device=device,topic=topic,is_event=False,epoch=epoch,\n",
    "                                topics_counter=topics_counter, topics_num=topics_num,\n",
    "                                threshold=entity_th)\n",
    "                # Events\n",
    "                print('Train event model and merge event clusters...')\n",
    "                logging.info('Train event model and merge event clusters...')\n",
    "                train_and_merge(clusterer, clusters=event_clusters, other_clusters=entity_clusters,\n",
    "                                model=cd_event_model, optimizer=cd_event_optimizer,\n",
    "                                loss=cd_event_loss,device=device,topic=topic,is_event=True,epoch=epoch,\n",
    "                                topics_counter=topics_counter, topics_num=topics_num,\n",
    "                                threshold=event_th)\n",
    "\n",
    "        print('Testing models on dev set...')\n",
    "        logging.info('Testing models on dev set...')\n",
    "\n",
    "        threshold_list = config_dict[\"dev_th_range\"]\n",
    "        improved = False\n",
    "        best_event_f1_for_th = 0\n",
    "        best_entity_f1_for_th = 0\n",
    "\n",
    "        if event_best_dev_f1 > 0:\n",
    "            best_saved_cd_event_model = load_check_point(os.path.join(args.out_dir,\n",
    "                                                                      'cd_event_best_model'))\n",
    "            best_saved_cd_event_model.to(device)\n",
    "        else:\n",
    "            best_saved_cd_event_model = cd_event_model\n",
    "\n",
    "        if entity_best_dev_f1 > 0:\n",
    "            best_saved_cd_entity_model = load_check_point(os.path.join(args.out_dir,\n",
    "                                                                       'cd_entity_best_model'))\n",
    "            best_saved_cd_entity_model.to(device)\n",
    "        else:\n",
    "            best_saved_cd_entity_model = cd_entity_model\n",
    "\n",
    "        for event_threshold in threshold_list:\n",
    "            for entity_threshold in threshold_list:\n",
    "                config_dict[\"event_merge_threshold\"] = event_threshold\n",
    "                config_dict[\"entity_merge_threshold\"] = entity_threshold\n",
    "                print('Testing models on dev set with threshold={}'.format((event_threshold,entity_threshold)))\n",
    "                logging.info('Testing models on dev set with threshold={}'.format((event_threshold,entity_threshold)))\n",
    "\n",
    "                # test event coref on dev\n",
    "                event_f1, _ = test_models(dev_set, cd_event_model, best_saved_cd_entity_model, device,\n",
    "                                                  config_dict, write_clusters=False, out_dir=args.out_dir,\n",
    "                                                  doc_to_entity_mentions=doc_to_entity_mentions, analyze_scores=False)\n",
    "\n",
    "                # test entity coref on dev\n",
    "                _, entity_f1 = test_models(dev_set, best_saved_cd_event_model, cd_entity_model, device,\n",
    "                                                  config_dict, write_clusters=False, out_dir=args.out_dir,\n",
    "                                                  doc_to_entity_mentions=doc_to_entity_mentions, analyze_scores=False)\n",
    "\n",
    "                if event_f1 > best_event_f1_for_th:\n",
    "                    best_event_f1_for_th = event_f1\n",
    "                    best_event_th = (event_threshold,entity_threshold)\n",
    "\n",
    "                if entity_f1 > best_entity_f1_for_th:\n",
    "                    best_entity_f1_for_th = entity_f1\n",
    "                    best_entity_th = (event_threshold,entity_threshold)\n",
    "\n",
    "        event_f1 = best_event_f1_for_th\n",
    "        entity_f1 = best_entity_f1_for_th\n",
    "        save_epoch_f1(event_f1, entity_f1, epoch, best_event_th, best_entity_th)\n",
    "\n",
    "        config_dict[\"event_merge_threshold\"] = orig_event_th\n",
    "        config_dict[\"entity_merge_threshold\"] = orig_entity_th\n",
    "\n",
    "        if event_f1 > event_best_dev_f1:\n",
    "            event_best_dev_f1 = event_f1\n",
    "            best_event_epoch = epoch\n",
    "            save_check_point(cd_event_model, os.path.join(args.out_dir, 'cd_event_best_model'))\n",
    "            improved = True\n",
    "            patient_counter = 0\n",
    "        if entity_f1 > entity_best_dev_f1:\n",
    "            entity_best_dev_f1 = entity_f1\n",
    "            best_entity_epoch = epoch\n",
    "            save_check_point(cd_entity_model, os.path.join(args.out_dir, 'cd_entity_best_model'))\n",
    "            improved = True\n",
    "            patient_counter = 0\n",
    "\n",
    "        if not improved:\n",
    "            patient_counter += 1\n",
    "\n",
    "        save_training_checkpoint(epoch, cd_event_model, cd_event_optimizer, event_best_dev_f1,\n",
    "                                 filename=os.path.join(args.out_dir, 'cd_event_model_state'))\n",
    "        save_training_checkpoint(epoch, cd_entity_model, cd_entity_optimizer, entity_best_dev_f1,\n",
    "                                 filename=os.path.join(args.out_dir, 'cd_entity_model_state'))\n",
    "\n",
    "        if patient_counter >= config_dict[\"patient\"]:\n",
    "            logging.info('Early Stopping!')\n",
    "            print('Early Stopping!')\n",
    "            save_summary(event_best_dev_f1, entity_best_dev_f1, best_event_epoch, best_entity_epoch, epoch)\n",
    "            break\n",
    "\n",
    "\n",
    "def train_and_merge(clusterer, clusters, other_clusters, model, optimizer,\n",
    "                    loss, device, topic ,is_event, epoch,\n",
    "                    topics_counter, topics_num, threshold):\n",
    "    '''\n",
    "    This function trains event/entity and then uses agglomerative clustering algorithm that\n",
    "    merges event/entity clusters\n",
    "    :param clusters: current event/entity clusters\n",
    "    :param other_clusters: should be the event current clusters if clusters = entity clusters\n",
    "    and vice versa.\n",
    "    :param model: event/entity model (according to clusters parameter)\n",
    "    :param optimizer: event/entity optimizer (according to clusters parameter)\n",
    "    :param loss: event/entity loss (according to clusters parameter)\n",
    "    :param device: gpu/cpu Pytorch device\n",
    "    :param topic: Topic object represents the current topic\n",
    "    :param is_event: whether to currently handle event mentions or entity mentions\n",
    "    :param epoch: current epoch number\n",
    "    :param topics_counter: the number of current topic\n",
    "    :param topics_num: total number of topics\n",
    "    :param threshold: merging threshold\n",
    "    :return:\n",
    "    '''\n",
    "\n",
    "    # Update arguments/predicates vectors according to the other clusters state\n",
    "    update_args_feature_vectors(clusters, other_clusters, model, device, is_event)\n",
    "\n",
    "    cluster_pairs,test_cluster_pairs \\\n",
    "        = generate_cluster_pairs(clusters, is_train=True)\n",
    "\n",
    "    # Train pairwise event/entity coreference scorer\n",
    "    train(cluster_pairs, model, optimizer, loss,\n",
    "          device, topic.docs, epoch, topics_counter, topics_num, config_dict, is_event,\n",
    "          other_clusters)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        update_lexical_vectors(clusters, model, device ,is_event, requires_grad=False)\n",
    "\n",
    "        event_mentions, entity_mentions = topic_to_mention_list(topic, is_gold=True)\n",
    "\n",
    "        # Update span representations after training\n",
    "        create_mention_span_representations(event_mentions, model, device, topic.docs, is_event=True,\n",
    "                                            requires_grad=False)\n",
    "        create_mention_span_representations(entity_mentions, model, device, topic.docs, is_event=False,\n",
    "                                            requires_grad=False)\n",
    "\n",
    "        cluster_pairs = test_cluster_pairs\n",
    "\n",
    "        # Merge clusters till reaching the threshold\n",
    "        merge(clusterer, clusters, cluster_pairs, other_clusters, model, device, topic.docs, epoch,\n",
    "              topics_counter, topics_num, threshold, is_event,\n",
    "              config_dict[\"use_args_feats\"], config_dict[\"use_binary_feats\"])\n",
    "\n",
    "\n",
    "def save_epoch_f1(event_f1, entity_f1, epoch,  best_event_th, best_entity_th):\n",
    "    '''\n",
    "    Write to a text file B-cubed F1 measures of both event and entity clustering\n",
    "    according to the models' predictions on the dev set after each training epoch.\n",
    "    :param event_f1: B-cubed F1 measure for event coreference\n",
    "    :param entity_f1: B-cubed F1 measure for entity coreference\n",
    "    :param epoch: current epoch number\n",
    "    :param best_event_th: best found merging threshold for event coreference\n",
    "    :param best_entity_th: best found merging threshold for event coreference\n",
    "    '''\n",
    "    f = open(os.path.join(args.out_dir,'epochs_scores.txt'),'a')\n",
    "    f.write('Epoch {} -  Event F1: {:.3f} with th = {}  Entity F1: {:.3f} with th = {}  \\n'.format(epoch,event_f1,best_event_th, entity_f1, best_entity_th))\n",
    "    f.close()\n",
    "\n",
    "\n",
    "def save_summary(best_event_score,best_entity_score, best_event_epoch,best_entity_epoch, total_epochs):\n",
    "    '''\n",
    "    Writes to a file a summary of the training (best scores, their epochs, and total number of\n",
    "    epochs)\n",
    "    :param best_event_score: best event coreference score on the dev set\n",
    "    :param best_entity_score: best entity coreference score on the dev set\n",
    "    :param best_event_epoch: the epoch of the best event coreference\n",
    "    :param best_entity_epoch: the epoch of the best entity coreference\n",
    "    :param total_epochs: total number of epochs\n",
    "    '''\n",
    "    f = open(os.path.join(args.out_dir, 'summary.txt'), 'w')\n",
    "    f.write('Best Event F1: {:.3f} epoch: {} \\n Best Entity F1: {:.3f} epoch: '\n",
    "            '{} \\n Training epochs: {}'.format(best_event_score,best_event_epoch,best_entity_score\n",
    "                                               ,best_entity_epoch, total_epochs))\n",
    "\n",
    "\n",
    "def save_training_checkpoint(epoch, model, optimizer, best_f1, filename):\n",
    "    '''\n",
    "    Saves model's checkpoint after each epoch\n",
    "    :param epoch: epoch number\n",
    "    :param model: the model to save\n",
    "    :param optimizer: Pytorch optimizer\n",
    "    :param best_f1: the best B-cubed F1 score so far\n",
    "    :param filename: the filename of the checkpoint file\n",
    "    '''\n",
    "    state = {'epoch': epoch + 1, 'state_dict': model.state_dict(),\n",
    "             'optimizer': optimizer.state_dict(), 'best_f1': best_f1 }\n",
    "    torch.save(state, filename)\n",
    "\n",
    "\n",
    "def load_training_checkpoint(model, optimizer, filename, device):\n",
    "    '''\n",
    "    Loads checkpoint from a file\n",
    "    :param model: an initialized model (CDCorefScorer)\n",
    "    :param optimizer: new Pytorch optimizer\n",
    "    :param filename: the checkpoint filename\n",
    "    :param device: gpu/cpu device\n",
    "    :return: model, optimizer, epoch, best_f1 loaded from the checkpoint.\n",
    "    '''\n",
    "    print(\"Loading checkpoint '{}'\".format(filename))\n",
    "    checkpoint = torch.load(filename)\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    best_f1 = checkpoint['best_f1']\n",
    "    print(\"Loaded checkpoint '{}' (epoch {})\"\n",
    "                .format(filename, checkpoint['epoch']))\n",
    "\n",
    "    model = model.to(device)\n",
    "    for state in optimizer.state.values():\n",
    "        for k, v in state.items():\n",
    "            if isinstance(v, torch.Tensor):\n",
    "                state[k] = v.to(device)\n",
    "\n",
    "    return model, optimizer, start_epoch, best_f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(config_dict[\"train_path\"], 'rb') as f:\n",
    "    train_set = cPickle.load(f)\n",
    "with open(config_dict[\"dev_path\"], 'rb') as f:\n",
    "    dev_set = cPickle.load(f)\n",
    "with open(\"data/feature_ELMO/test_data\", 'rb') as f:\n",
    "    test_set = cPickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = train_set.topics  # Use the gold sub-topics\n",
    "topics_num = len(topics.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<classes.Corpus at 0x7f5cf81e7e80>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hdbscan\n",
    "clusterer = hdbscan.HDBSCAN()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kmeans_pytorch import kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create new models...\n",
      "Loaded GloVe!\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "\n",
    "doc_to_entity_mentions = load_entity_wd_clusters(config_dict)  # loads predicted WD entity coref chains from external tool\n",
    "\n",
    "print('Create new models...')\n",
    "logging.info('Create new models...')\n",
    "factory_load_embeddings(config_dict)  # loading pre-trained embeddings before creating new models\n",
    "cd_event_model = create_model(config_dict)\n",
    "cd_entity_model = create_model(config_dict)\n",
    "\n",
    "cd_event_model = cd_event_model.to(device)\n",
    "cd_entity_model = cd_entity_model.to(device)\n",
    "\n",
    "cd_event_optimizer = create_optimizer(config_dict, cd_event_model)\n",
    "cd_entity_optimizer = create_optimizer(config_dict, cd_entity_model)\n",
    "\n",
    "cd_event_loss = create_loss(config_dict)\n",
    "cd_entity_loss = create_loss(config_dict)\n",
    "\n",
    "topics = train_set.topics  # Use the gold sub-topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_counter = 0\n",
    "topics_keys = list(topics.keys())\n",
    "random.shuffle(topics_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['29_ecbplus',\n",
       " '29_ecb',\n",
       " '26_ecb',\n",
       " '8_ecbplus',\n",
       " '30_ecbplus',\n",
       " '16_ecb',\n",
       " '33_ecbplus',\n",
       " '16_ecbplus',\n",
       " '3_ecb',\n",
       " '9_ecb',\n",
       " '19_ecbplus',\n",
       " '32_ecbplus',\n",
       " '10_ecbplus',\n",
       " '26_ecbplus',\n",
       " '14_ecbplus',\n",
       " '19_ecb',\n",
       " '14_ecb',\n",
       " '25_ecb',\n",
       " '22_ecbplus',\n",
       " '20_ecbplus',\n",
       " '1_ecbplus',\n",
       " '7_ecb',\n",
       " '6_ecbplus',\n",
       " '6_ecb',\n",
       " '28_ecb',\n",
       " '3_ecbplus',\n",
       " '22_ecb',\n",
       " '13_ecb',\n",
       " '32_ecb',\n",
       " '7_ecbplus',\n",
       " '28_ecbplus',\n",
       " '4_ecbplus',\n",
       " '13_ecbplus',\n",
       " '25_ecbplus',\n",
       " '20_ecb',\n",
       " '8_ecb',\n",
       " '11_ecb',\n",
       " '4_ecb',\n",
       " '10_ecb',\n",
       " '1_ecb',\n",
       " '30_ecb',\n",
       " '24_ecb',\n",
       " '31_ecb',\n",
       " '24_ecbplus',\n",
       " '27_ecbplus',\n",
       " '31_ecbplus',\n",
       " '33_ecb',\n",
       " '11_ecbplus',\n",
       " '9_ecbplus',\n",
       " '27_ecb']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cross topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get all mentions\n",
    "all_event_mentions = []\n",
    "all_entity_mentions = []\n",
    "for topic_id in topics_keys:\n",
    "    # init event and entity clusters\n",
    "    topic = topics[topic_id]\n",
    "    event_mentions, entity_mentions = topic_to_mention_list(topic, is_gold=True)\n",
    "    all_event_mentions.extend(event_mentions)\n",
    "    all_entity_mentions.extend(event_mentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_event_bow_arg_vec(mentions, model, device):\n",
    "    for event_mention in mentions:\n",
    "        event_mention.arg0_vec = torch.zeros(model.embedding_dim + model.char_hidden_dim, requires_grad=False).to(device).view(1, -1)\n",
    "        event_mention.arg1_vec = torch.zeros(model.embedding_dim + model.char_hidden_dim, requires_grad=False).to(device).view(1, -1)\n",
    "        event_mention.time_vec = torch.zeros(model.embedding_dim + model.char_hidden_dim, requires_grad=False).to(device).view(1, -1)\n",
    "        event_mention.loc_vec = torch.zeros(model.embedding_dim + model.char_hidden_dim, requires_grad=False).to(device).view(1, -1)\n",
    "\n",
    "def create_entity_bow_predicate_vec(mentions, model, device):\n",
    "\n",
    "    for entity_mention in mentions:\n",
    "        entity_mention.arg0_vec = torch.zeros(model.embedding_dim + model.char_hidden_dim, requires_grad=False).to(device).view(1, -1)\n",
    "        entity_mention.arg1_vec = torch.zeros(model.embedding_dim + model.char_hidden_dim, requires_grad=False).to(device).view(1, -1)\n",
    "        entity_mention.time_vec = torch.zeros(model.embedding_dim + model.char_hidden_dim, requires_grad=False).to(device).view(1, -1)\n",
    "        entity_mention.loc_vec = torch.zeros(model.embedding_dim + model.char_hidden_dim, requires_grad=False).to(device).view(1, -1)\n",
    "                \n",
    "                \n",
    "def create_event_bow_lexical_vec(event_mention, model, device):\n",
    "\n",
    "    if config_dict[\"use_char_embeds\"]:\n",
    "        bow_vec = torch.zeros(model.embedding_dim + model.char_hidden_dim,\n",
    "                              requires_grad=config_dict[\"requires_grad\"]).to(device).view(1, -1)\n",
    "    else:\n",
    "        bow_vec = torch.zeros(model.embedding_dim, requires_grad=config_dict[\"requires_grad\"]).to(device).view(1, -1)\n",
    "    \n",
    "    # creating lexical vector using the head word of each event mention in the cluster\n",
    "    head = event_mention.mention_head\n",
    "    head_tensor = find_word_embed(head, model, device)\n",
    "    if config_dict[\"use_char_embeds\"]:\n",
    "        char_tensor = get_char_embed(head, model, device)\n",
    "        if not config_dict[\"requires_grad\"]:\n",
    "            char_tensor = char_tensor.detach()\n",
    "        cat_tensor = torch.cat([head_tensor, char_tensor], 1)\n",
    "    else:\n",
    "        cat_tensor = head_tensor\n",
    "    bow_vec += cat_tensor\n",
    "\n",
    "    event_mention.lexical_vec = bow_vec\n",
    "\n",
    "\n",
    "def create_entity_bow_lexical_vec(entity_mention, model, device):\n",
    "    if config_dict[\"use_char_embeds\"]:\n",
    "        bow_vec = torch.zeros(model.embedding_dim + model.char_hidden_dim,\n",
    "                              requires_grad=config_dict[\"requires_grad\"]).to(device).view(1, -1)\n",
    "    else:\n",
    "        bow_vec = torch.zeros(model.embedding_dim,requires_grad=config_dict[\"requires_grad\"]).to(device).view(1, -1)\n",
    "\n",
    "    # creating lexical vector using each entity mention in the cluster\n",
    "    mention_bow = torch.zeros(model.embedding_dim,requires_grad=config_dict[\"requires_grad\"]).to(device).view(1, -1)\n",
    "    mention_embeds = [find_word_embed(token, model, device)\n",
    "                      for token in entity_mention.get_tokens()\n",
    "                      if not is_stop(token)]\n",
    "    if config_dict[\"use_char_embeds\"]:\n",
    "        char_embeds = get_char_embed(entity_mention.mention_str, model, device)\n",
    "\n",
    "    for word_tensor in mention_embeds:\n",
    "        mention_bow += word_tensor\n",
    "\n",
    "    mention_bow /= len(entity_mention.get_tokens())\n",
    "\n",
    "    if config_dict[\"use_char_embeds\"]:\n",
    "        if not config_dict[\"requires_grad\"]:\n",
    "            char_embeds = char_embeds.detach()\n",
    "\n",
    "        cat_tensor = torch.cat([mention_bow, char_embeds], 1)\n",
    "    else:\n",
    "        cat_tensor = mention_bow\n",
    "    bow_vec += cat_tensor\n",
    "    \n",
    "    entity_mention.lexical_vec = bow_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_args_feature_vectors(mentions, model ,device, is_event):\n",
    "    if is_event:\n",
    "        create_event_bow_arg_vec(mentions, model, device)\n",
    "    else:\n",
    "        create_entity_bow_predicate_vec(mentions, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_lexical_vectors(mentions, model, device, is_event):    \n",
    "    if is_event:\n",
    "        create_event_bow_lexical_vec(mentions, model, device)\n",
    "    else:\n",
    "        create_entity_bow_lexical_vec(mentions, model, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_args_feature_vectors(all_entity_mentions, cd_event_model, device, True)\n",
    "update_args_feature_vectors(all_entity_mentions, cd_entity_model, device, False)\n",
    "for mention in all_event_mentions:\n",
    "    update_lexical_vectors(mention, cd_event_model, device, True)\n",
    "    \n",
    "for metion in all_entity_mentions:\n",
    "    update_lexical_vectors(mention, cd_entity_model, device, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mention_span_rep(mention, device, model, config_dict, is_event):\n",
    "    if is_event:\n",
    "        head = mention.mention_head\n",
    "        head_tensor = find_word_embed(head, model, device)\n",
    "        char_embeds = get_char_embed(head, model, device)\n",
    "        mention_tensor = torch.cat([head_tensor, char_embeds], 1)\n",
    "    else:\n",
    "        mention_bow = torch.zeros(model.embedding_dim, requires_grad=config_dict[\"requires_grad\"]).to(device).view(1, -1)\n",
    "        mention_embeds = [find_word_embed(token, model, device) for token in mention.get_tokens()\n",
    "                          if not is_stop(token)]\n",
    "\n",
    "        for mention_word_tensor in mention_embeds:\n",
    "            mention_bow += mention_word_tensor\n",
    "        char_embeds = get_char_embed(mention.mention_str, model, device)\n",
    "\n",
    "        if len(mention_embeds) > 0:\n",
    "            mention_bow = mention_bow / float(len(mention_embeds))\n",
    "\n",
    "        mention_tensor = torch.cat([mention_bow, char_embeds], 1)\n",
    "\n",
    "    if config_dict[\"use_head_embeddings\"]:\n",
    "        span_tensor = mention.head_embeddings.to(device).view(1,-1)\n",
    "        mention_span_rep = torch.cat([span_tensor, mention_tensor], 1)\n",
    "    else:\n",
    "        mention_span_rep = mention_tensor\n",
    "\n",
    "    if config_dict[\"requires_grad\"]:\n",
    "        if mention_span_rep.requires_grad:\n",
    "            mention_span_rep = mention_span_rep.detach()\n",
    "    return mention_span_rep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mention in all_event_mentions:\n",
    "    mention.span_rep = get_mention_span_rep(mention, device, cd_entity_model, config_dict=config_dict, is_event=True)\n",
    "    \n",
    "for mention in all_entity_mentions:\n",
    "    mention.span_rep = get_mention_span_rep(mention, device, cd_entity_model, config_dict=config_dict, is_event=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_entity_mentions_span_rep = [mention.span_rep[0] for mention in all_entity_mentions]\n",
    "all_event_mentions_span_rep = [mention.span_rep[0] for mention in all_event_mentions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "380"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = int(len(all_entity_mentions_span_rep_stack)/10)\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "[running kmeans]: 0it [00:00, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running k-means on cuda:0..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "[running kmeans]: 0it [00:00, ?it/s, center_shift=500627.687500, iteration=1, tol=0.000100]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "[running kmeans]: 1it [00:00,  3.43it/s, center_shift=500627.687500, iteration=1, tol=0.000100]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "[running kmeans]: 1it [00:00,  3.43it/s, center_shift=nan, iteration=2, tol=0.000100]          \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "[running kmeans]: 2it [00:00,  3.50it/s, center_shift=nan, iteration=2, tol=0.000100]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "[running kmeans]: 2it [00:00,  3.50it/s, center_shift=nan, iteration=3, tol=0.000100]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "[running kmeans]: 3it [00:00,  3.66it/s, center_shift=nan, iteration=3, tol=0.000100]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "[running kmeans]: 3it [00:01,  3.66it/s, center_shift=nan, iteration=4, tol=0.000100]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "[running kmeans]: 4it [00:01,  3.74it/s, center_shift=nan, iteration=4, tol=0.000100]\u001b[A\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "cluster_id_x, cluster_centers = kmeans(X=all_entity_mentions_span_rep_stack, num_clusters=n, distance=\"cosine\",device=torch.device('cuda:0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[running kmeans]: 23it [00:04,  4.68it/s, center_shift=0.000000, iteration=23, tol=0.000100]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'c' argument has 3808 elements, which is not acceptable for use with 'x' with size 1000, 'y' with size 1000.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/joint/lib/python3.6/site-packages/matplotlib/colors.py\u001b[0m in \u001b[0;36mto_rgba\u001b[0;34m(c, alpha)\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0mrgba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_colors_full_map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Not in cache, or unhashable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: (tensor(1), None)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/joint/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs)\u001b[0m\n\u001b[1;32m   4231\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Then is 'c' acceptable as PathCollection facecolors?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4232\u001b[0;31m                 \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmcolors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_rgba_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4233\u001b[0m                 \u001b[0mn_elem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/joint/lib/python3.6/site-packages/matplotlib/colors.py\u001b[0m in \u001b[0;36mto_rgba_array\u001b[0;34m(c, alpha)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m         \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_rgba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/joint/lib/python3.6/site-packages/matplotlib/colors.py\u001b[0m in \u001b[0;36mto_rgba\u001b[0;34m(c, alpha)\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Not in cache, or unhashable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m         \u001b[0mrgba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_to_rgba_no_colorcycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/joint/lib/python3.6/site-packages/matplotlib/colors.py\u001b[0m in \u001b[0;36m_to_rgba_no_colorcycle\u001b[0;34m(c, alpha)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;31m# Test dimensionality to reject single floats.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid RGBA argument: {!r}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m     \u001b[0;31m# Return a tuple to prevent the cached value from being modified.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid RGBA argument: tensor(1)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-117-c0a0c657e1a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m160\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcluster_id_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cool'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m plt.scatter(\n\u001b[1;32m      7\u001b[0m     \u001b[0mcluster_centers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcluster_centers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/joint/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, data, **kwargs)\u001b[0m\n\u001b[1;32m   2862\u001b[0m         \u001b[0mvmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlinewidths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2863\u001b[0m         verts=verts, edgecolors=edgecolors, **({\"data\": data} if data\n\u001b[0;32m-> 2864\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2865\u001b[0m     \u001b[0msci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2866\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/joint/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1808\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1810\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[0;32m~/anaconda3/envs/joint/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs)\u001b[0m\n\u001b[1;32m   4243\u001b[0m                         \u001b[0;34m\"acceptable for use with 'x' with size {xs}, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4244\u001b[0m                         \u001b[0;34m\"'y' with size {ys}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4245\u001b[0;31m                         \u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_elem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4246\u001b[0m                     )\n\u001b[1;32m   4247\u001b[0m                 \u001b[0;31m# Both the mapping *and* the RGBA conversion failed: pretty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 'c' argument has 3808 elements, which is not acceptable for use with 'x' with size 1000, 'y' with size 1000."
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAAG1CAYAAAA/aGqTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAYmwAAGJsBSXWDlAAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3X+07WVdJ/D3R0FUfiak0L2gpETN1Cp+qREuJyUpDAMVZcjRyhxTUXLlInT8MWtcEWSTaGb+mAyrwUYxzWVoJUQJxQjiEDaDlXGBewMcAoF7VX7IM3/s74kz23v2Pec833PP8Z7Xa629nv3dz7M/+9k8nHPe97u/+/ut1loAAFi+h632BAAAvt0JVAAAnQQqAIBOAhUAQCeBCgCgk0AFANBJoAIA6CRQAQB0EqgAADoJVAAAnQQqAIBOAhUAQCeBCgCgk0AFANBJoAIA6DRqoKqqw6vq1VV1QVVdV1UPVFWrqjd21j2+qi6uqtur6utVdX1V/UpV7TXW3AEAlmu3keu9IsmZYxasqtcm+Y0kLclnk9yW5GlJ3pDkeVV1XGvt9jFfEwBgKcb+yO+LSX49yU8n+b4kv99TrKqOSPJfk3wzybNba09vrb0gyROTXJLk8CTv6ZoxAECnUfdQtdb+2/ztqnqws+Trk1SS322tfWre63ytql6a5J8y2Uv1va216ztfCwBgWdbsQelV9Ygkzx42L5zub63dmOSKYfOUnTUvAIBpazZQJfmeJI8e7l+9wJi5x49Y+ekAAGzf2Aelj+nQof1qa+2eBcbcPDV2pqraPKP7u5I8kOQri5seALAGPDbJ/a21PVdzEms5UO09tNtmjNk6tPuM8Hr1sIc9bPeDDjpowwi1AICd4JZbbsmDD/Yest1vLQeq0bXWNi7UV1WbDzrooA2bN8/aiQUArCUbN27Mli1bVv3TpbV8DNXcx3yzduHNndjz7hWeCwDAgtZyoNo0tPtV1d4LjDl4aiwAwE63lgPVl5J8bbh/9AJj5h6/ZuWnAwCwfWs2ULXW7kvyJ8Pm6dP9VfX4JMcOmx/bWfMCAJi26oGqqs4YLnb8e9vpPjeTa/j9bFX9+LznPDrJ7yR5eJKPOks6ALCaRv2WX1UdmeTd8x564tC+vKp+ct7jp7TWbhnuH5DJNfluna7XWrumqn4pk4sjX1xVf5nJeaKeluSgTD4W/IUx3wMAwFKNfdqEfZI8ZTuPbxxuc/ZYbMHW2tur6rokv5TkyZl86++mJL+a5FdnnPQTAGCnqNbaas9hTaiqzRs2bHAeKgD4NjKch2rLrHNN7gyrfgwVAMC3O4EKAKCTQAUA0EmgAgDoJFABAHQSqAAAOglUAACdBCoAgE4CFQBAJ4EKAKCTQAUA0EmgAgDoJFABAHQSqAAAOglUAACdBCoAgE4CFQBAJ4EKAKCTQAUA0EmgAgDoJFABAHQSqAAAOglUAACdBCoAgE4CFQBAJ4EKAKCTQAUA0EmgAgDoJFABAHQSqAAAOglUAACdBCoAgE4CFQBAJ4EKAKCTQAUA0EmgAgDoJFABAHQSqAAAOglUAACdBCoAgE4CFQBAJ4EKAKCTQAUA0EmgAgDoJFABAHQSqAAAOglUAACdBCoAgE4CFQBAJ4EKAKCTQAUA0EmgAgDoJFABAHQSqAAAOglUAACdViRQVdWpVXVZVd1ZVduq6tqqOquqdl9GrT2r6vVVdXVV3V1V91fVrVX1yap6zkrMHwBgKXYbu2BVnZ/kzCQPJLk0ydYkz0hyXpKTqupZrbWvL7LW/kn+Ksm/Ger8dZKvJnlSkmcneXZVvbO1dubY7wMAYLFG3UNVVSdnEqa2JnlKa+2E1trzkhyW5LokxyV56xJKvjmTMPX5JI8f6r2wtXZUJoHqgSSvqaqnjvk+AACWYuyP/N4wtOe21q6Ze7C1dnuSVw6bZ1TVvous94yhPa+1dsf8jtbaxUn+Ytj84WXOFwCg22iBqqo2JDlm2Lxwur+1dnmSm5PskeTERZb9xiLH3b7IcQAAoxtzD9URQ3tHa+2GBcZcPTV2Rz41tL9cVY+Z31FVJyb50SS3JvnEUiYKADCmMQ9KP3Rob5ox5uapsTtyXpInJzkhyY1VdUUeOij9qCRXJHlpa+2upU8XAGAcYwaqvYd224wxW4d2n8UUbK1tq6qTkpyT5JcyCVZz/iXJZ5JsWewEq2rzjO4DF1sHAGC+NX1iz6o6KJO9UK9O8sYk351kr0z2Wn0+yVuSXF5Vey9YBABghY25h+qeod1zxpi9hvbuRdb8YCYHup/VWnvbvMevqqqfzCRU/WCS12USrmZqrW1cqG/Ye7VhkfMCAPhXY+6h2jS0B88YM9e3acaYJP/6rcEfGzY/NN3fWrs/yUXD5vGLmiEAwAoYM1B9YWj3r6qFDjo/emivWaB/vkPm3V9oj9bcweiPWaAfAGDFjRaoWmubk1w1bJ4+3V9Vx2Wyh+reJBcvouT8g82fssCYuTOkL3SaBgCAFTf2QennDO3ZVXXk3IPDNfnePWy+a/5pDqrqlKq6vqoumV+otXZTHgpo76iqJ8zvr6oXJXnhsPktJxIFANhZRr04cmvt41X1ziSvSXLlEJK2JXlmkv0y+cbem6aetm+Sw5M8cjslfy6Ty8t8X5L/U1VXZnJW9O9L8m+HMX+Q5L+P+T4AAJZi1ECVJK21M4cTcL4qybFJdk/y5STnJnl7a+2+JdT6YlV9f5LXJvmJTL7xt0eSO5P8aZIPtNY+PPJbAABYkmqtrfYc1oSq2rxhw4YNmzfPOvcnALCWbNy4MVu2bNky69RIO8OaPrEnAMC3A4EKAKCTQAUA0EmgAgDoJFABAHQSqAAAOglUAACdBCoAgE4CFQBAJ4EKAKCTQAUA0EmgAgDoJFABAHQSqAAAOglUAACdBCoAgE4CFQBAJ4EKAKCTQAUA0EmgAgDoJFABAHQSqAAAOglUAACdBCoAgE4CFQBAJ4EKAKCTQAUA0EmgAgDoJFABAHQSqAAAOglUAACdBCoAgE4CFQBAJ4EKAKCTQAUA0EmgAgDoJFABAHQSqAAAOglUAACdBCoAgE4CFQBAJ4EKAKCTQAUA0EmgAgDoJFABAHQSqAAAOglUAACdBCoAgE4CFQBAJ4EKAKCTQAUA0EmgAgDoJFABAHQSqAAAOglUAACdBCoAgE4rEqiq6tSquqyq7qyqbVV1bVWdVVW7d9T8qar6RFXdWlX3VdVXquqvq+rNY84dAGCpRg9UVXV+kg8n+ZEkn0vy6SSHJDkvyaVV9agl1ntEVX04yceTHJ/k75JclOSLSZ6Y5DXjzR4AYOl2G7NYVZ2c5MwkW5M8vbV2zfD4AUkuTXJckrcmed0Syr4/yamZBKqXtdZun/d6D0vy5HFmDwCwPGPvoXrD0J47F6aSZAhBrxw2z6iqfRdTrKqemeTFmeyNesH8MDXUfbC1dmX/tAEAlm+0QFVVG5IcM2xeON3fWrs8yc1J9khy4iLLvnpoz2+t3d89SQCAFTDmR35HDO0drbUbFhhzdZKDh7EfmlWsqh6e5JnD5l9V1YFJTktyeJJ7k3whyUdba1t7Jw4A0GPMQHXo0N40Y8zNU2Nn+e4kew33n5rk3fO257ytqk5rrV26mAlW1eYZ3QcupgYAwLQxj6Hae2i3zRgztzdpn0XU23/e/d9J8vlMPlLcO8kPJbk4yXcm+eOqOmxpUwUAGM+o3/IbWc27vyXJCa21e4fta6vqOUn+V5LvT3J2kpfuqGBrbeOCLzbZe7Vh+dMFANarMfdQ3TO0e84YM/eR3d1LqJckF8wLU0mS1to3k7x32Dx+UTMEAFgBYwaqTUN78Iwxc32bZoyZX68N9/9pgTFzjx+0iHoAACtizED1haHdv6oWOuj86KG9ZoH+fzV8e+9Lw+YBCwybe9w3/QCAVTNaoGqtbU5y1bB5+nR/VR2XyR6qezM5oHwxPjK0C32k92ND+7lF1gMAGN3YZ0o/Z2jPrqoj5x6sqv0zOe1BkryrtXbXvL5Tqur6qrpkO/XemeTOJCdW1cvnd1TVaUl+et44AIBVMWqgaq19PJNws1eSK6vqU1V1UZJ/TPIDSa5I8qapp+2byck6n7idercneWGSbyR5T1V9sao+UlXXZHJi0Ery1tbaYvd4AQCMbuw9VGmtnZlJCPqbJMdmcpmZzZmc2uAZrbWvL7Henyf5wSQfTLJfkp9KckgmHxue0Fp783izBwBYumqt7XjUOlBVmzds2LBh8+ZZJ1MHANaSjRs3ZsuWLVtmnWtyZxh9DxUAwHojUAEAdBKoAAA6CVQAAJ0EKgCATgIVAEAngQoAoJNABQDQSaACAOgkUAEAdBKoAAA6CVQAAJ0EKgCATgIVAEAngQoAoJNABQDQSaACAOgkUAEAdBKoAAA6CVQAAJ0EKgCATgIVAEAngQoAoJNABQDQSaACAOgkUAEAdBKoAAA6CVQAAJ0EKgCATgIVAEAngQoAoJNABQDQSaACAOgkUAEAdBKoAAA6CVQAAJ0EKgCATgIVAEAngQoAoJNABQDQSaACAOgkUAEAdBKoAAA6CVQAAJ0EKgCATgIVAEAngQoAoJNABQDQSaACAOgkUAEAdBKoAAA6CVQAAJ0EKgCATgIVAEAngQoAoNOKBKqqOrWqLquqO6tqW1VdW1VnVdXuI9Q+saracPvMGPMFAOgxeqCqqvOTfDjJjyT5XJJPJzkkyXlJLq2qR3XU/o4k70/SRpgqAMAoRg1UVXVykjOTbE3ylNbaCa215yU5LMl1SY5L8taOl/jNJI9L8p7euQIAjGXsPVRvGNpzW2vXzD3YWrs9ySuHzTOqat+lFq6qU5L8dJLfyGTPFwDAmjBaoKqqDUmOGTYvnO5vrV2e5OYkeyQ5cYm1D8hkr9SXkry5b6YAAOMacw/VEUN7R2vthgXGXD01drF+O8kBSV7aWvvGciYHALBSdhux1qFDe9OMMTdPjd2hqjotyfOTvKO1dsUy5zZXa/OM7gN7agMA69eYe6j2HtptM8ZsHdp9FlOwqg5M8ltJvpyHjs8CAFhTxtxDtRLel+Q7kjyvtfa13mKttY0L9Q17rzb0vgYAsP6MuYfqnqHdc8aYvYb27h0Vq6qXJDkpyXtaa5f1TQ0AYOWMuYdq09AePGPMXN+mGWPmnDK0x1TVZVN9c8c7HTWv77TW2q2LqAsAMKoxA9UXhnb/qjp0gW/6HT2012ynbyFHz+jbL8nTh/uPXEJNAIDRjPaRX2ttc5Krhs3Tp/ur6rhM9lDdm+TiRdQ7ubVW27sl+dlh2CXzHt80zjsBAFiasc+Ufs7Qnl1VR849WFX7J3n3sPmu1tpd8/pOqarrq+qSkecCALBTjPotv9bax6vqnUlek+TKISRtS/LMTD6euyLJm6aetm+Sw+MjOwDg29TYe6jSWjszyQuT/E2SYzO5zMzmJGcneUZr7etjvyYAwGqq1tpqz2FNqKrNGzZs2LB586yTqQMAa8nGjRuzZcuWLbPONbkzjL6HCgBgvRGoAAA6CVQAAJ0EKgCATgIVAEAngQoAoJNABQDQSaACAOgkUAEAdBKoAAA6CVQAAJ0EKgCATgIVAEAngQoAoJNABQDQSaACAOgkUAEAdBKoAAA6CVQAAJ0EKgCATgIVAEAngQoAoJNABQDQSaACAOgkUAEAdBKoAAA6CVQAAJ0EKgCATgIVAEAngQoAoJNABQDQSaACAOgkUAEAdBKoAAA6CVQAAJ0EKgCATgIVAEAngQoAoJNABQDQSaACAOgkUAEAdBKoAAA6CVQAAJ0EKgCATgIVAEAngQoAoJNABQDQSaACAOgkUAEAdBKoAAA6CVQAAJ0EKgCATgIVAEAngQoAoJNABQDQSaACAOi0IoGqqk6tqsuq6s6q2lZV11bVWVW1+xLrHFFVr6+qS6rqtqq6f6j52ap61VLrAQCshN3GLlhV5yc5M8kDSS5NsjXJM5Kcl+SkqnpWa+3ri6izW5Jrhs2tSa5KcluSjUl+OMlxSV5cVSe01r469vsAAFisUfdQVdXJmYSprUme0lo7obX2vCSHJbkukxD01iWU/HySFyQ5oLX2jNbav2+tPS3JEUluSfLkJL8x5nsAAFiqsT/ye8PQnttam9u7lNba7UleOWyeUVX77qhQa+2B1trRrbWPtNbuneq7LslZw+ZpPvoDAFbTaIGqqjYkOWbYvHC6v7V2eZKbk+yR5MQRXvILQ/uoJAeMUA8AYFnG3EN1xNDe0Vq7YYExV0+N7XHY0N6X5I4R6gEALMuYB6UfOrQ3zRhz89TYZamqykMf+X1y+iPBGc/bPKP7wJ45AQDr15h7qPYe2m0zxmwd2n06X+stmXzTb2uSsztrAQB0Gf20CSutql6c5M1JHkzyc621f1jsc1trG2fU3ZxkQ/8MAYD1Zsw9VPcM7Z4zxuw1tHcv5wWq6tQkHxg2X9Za+8hy6gAAjGnMQLVpaA+eMWaub9OMMdtVVc/N5NuDD0vy8tbaB3bwFACAnWLMQDV3GoP9q2qhg86PHtprFujfruGEoX+Y5OFJXtFae//ypggAML7RAlVrbXMml4dJktOn+6vquEz2UN2b5OLF1q2qk5J8OJPjvV7RWntv/2wBAMYz9pnSzxnas6vqyLkHq2r/JO8eNt/VWrtrXt8pVXV9VV0yXayqTkxyUSZh6heEKQBgLRr1W36ttY9X1TuTvCbJlUNI2pbkmUn2S3JFkjdNPW3fJIcneeT8B6vqsUn+KMkjkmxOcmxVHbvAS79uuLwNAMBON/ppE1prZ1bVFUleleTYJLsn+XKSc5O8vbV23yJLPTqTy9QkycYkL5kx9j8nEagAgFWxIuehaq19OJPjnhYz9oIkF2zn8U1Jasx5AQCshLGPoQIAWHcEKgCATgIVAEAngQoAoJNABQDQSaACAOgkUAEAdBKoAAA6CVQAAJ0EKgCATgIVAEAngQoAoJNABQDQSaACAOgkUAEAdBKoAAA6CVQAAJ0EKgCATgIVAEAngQoAoJNABQDQSaACAOgkUAEAdBKoAAA6CVQAAJ0EKgCATgIVAEAngQoAoJNABQDQSaACAOgkUAEAdBKoAAA6CVQAAJ0EKgCATgIVAEAngQoAoJNABQDQSaACAOgkUAEAdBKoAAA6CVQAAJ0EKgCATgIVAEAngQoAoJNABQDQSaACAOgkUAEAdBKoAAA6CVQAAJ0EKgCATgIVAEAngQoAoJNABQDQSaACAOgkUAEAdFqRQFVVp1bVZVV1Z1Vtq6prq+qsqtp9mfWOqqqPVNVtVfWNqrqhqn6zqh479twBAJZq9EBVVecn+XCSH0nyuSSfTnJIkvOSXFpVj1pivecnuTLJ85PcmOSPkzyY5Iwkf1tVTxpv9gAASzdqoKqqk5OcmWRrkqe01k5orT0vyWFJrktyXJK3LqHedyX5YJLdkry8tfbk1toLk3xPkj9I8rgkF1ZVjfk+AACWYuw9VG8Y2nNba9fMPdhauz3JK4fNM6pq30XW+8Ukj07ymdba++bV+2aSVyS5K8kxSZ7VO3EAgOUaLVBV1YZMwk2SXDjd31q7PMnNSfZIcuIiy54yo97WJJ8YNp+7pMkCAIxozD1URwztHa21GxYYc/XU2AVV1d5J5o6PunqBYYuuBwCwUnYbsdahQ3vTjDE3T42d5Qnz7i9Ucyn1UlWbZ3RvuOWWW7Jx48bFlAIA1oBbbrklSVb9W/9jBqq9h3bbjDFbh3afJdSbVXMp9XbowQcfzJYtW7aMUYsuBw7tras6CxJrsdZYj7XDWqwdGzJunlmWVZ/AztRaW3D309zeq1lj2DmsxdphLdYW67F2WIu1YwefPu00Yx5Ddc/Q7jljzF5De/cS6s2quZR6AAArYsxAtWloD54xZq5v04wxc26cd/+QEeoBAKyIMQPVF4Z2/6pa6CDxo4f2mgX6/1Vr7e4k/zj1vGXXAwBYKaMFqtba5iRXDZunT/dX1XGZ7FG6N8nFiyz7sRn19kpy0rD5R0uaLADAiMY+U/o5Q3t2VR0592BV7Z/k3cPmu1prd83rO6Wqrq+qS7ZT7/wkX0tyfFW9bN5zHj7U2y+TEPdn474NAIDFGzVQtdY+nuSdmRwsfmVVfaqqLsrko7sfSHJFkjdNPW3fJIcneeJ26v1zkp9J8s0k76uqK6vqD5P8fZL/kOS2JKe31tqY7wMAYClqJbJIVb0gyauS/FCS3ZN8OZOLGb+9tXbf1NifSfK7SW5srT1hgXpHZXKdwKdlEsBuSfLJJG9trd02+hsAAFiCFQlUAADrydjHUAEArDsCFQBAJ4EKAKCTQAUA0EmgAgDoJFABAHQSqAAAOu2ygaqqTq2qy6rqzqraVlXXVtVZVbX7MusdVVUfqarbquobVXVDVf1mVT127LnvasZai6o6oqpeX1WXDOtw/1Dzs1X1quWu7Xoy9s/FVO0Tq6oNt8+MMd9d2UqsRVX9VFV9oqpurar7quorVfXXVfXmMee+KxpzPapqz+F31dVVdffwu+rWqvpkVT1nJea/K6iqw6vq1VV1QVVdV1UPDL9P3thZ9/iquriqbq+qrw+Xu/uV4ZrA42mt7XK3TK4B2JLcn+RPk3w0yZ3DY59N8qgl1nv+UKsl+VyS/5HJ2d9bkluTPGm13/NavY21Fkl2G57TktyT5NIkHxpqPDA8/j+T7Lfa73mt3sb+uZiq/R1JtiR5cKj3mdV+v2v5tgK/ox6R5MPD87+W5JIkFw4/J7cluX213/Navo25Hkn2T/J3835X/enwN+Pz836HvWO13/NavM1bh+nbGztqvnao8WCSvxx+Tm4ZHrs+yQGjzX+1/wOuwIKcPO9/5CPnPX5Akr8d+n59CfW+K8m24Xn/cd7jD0/y+/NCVq32e19rtzHXYghUVyc5NckeU30/kOSfh3ofWO33vRZvY/9cbKf+H2QSbN8tUO38tUjyweF5H5v+A5HJJxFPXe33vVZvK/A34x3Dc65O8pipvhPz0D/Orcm3/rf7+SRvS3J6ku9N8ns9gSrJEUOQeiDJT8x7/NFJPjPUvmi0+a/2f8AVWJDPDf+R/tN2+o4b+r6RZN9F1vu14Tl/vp2+vZJ8deg/YbXf+1q7jb0WO3itF+Whf53vvtrvfa3dVnItkpwyPP/XMrmYuUC1E9ciyTOH51zn//01sR7XDc85dYH+Pxv6X7va732t35Jc0Bmo5vbavn87fY9P8s2h/3vHmO8udQxVVW1IcsyweeF0f2vt8iQ3J9kjk38pLMYpM+ptTfKJYfO5S5rsLm6F1mKWLwztozL5lyWDlVyLqjogyXuSfCmJ43R2YIXW4tVDe35r7f7uSa4jK7Qe31jkuNsXOY5lqKpHJHn2sLm9tb0xyRXD5inT/cuxSwWqTHbvJckdrbUbFhhz9dTYBVXV3kmeNPW8ZddbZ0Zdi0U4bGjvS3LHCPV2JSu5Fr+dSYB9aWttsX9I1rOxf0c9PJM9VEnyV1V1YFX9YlX9dlWdX1UvGf3A213LSvxsfGpof7mqHjO/o6pOTPKjmRx7+4npJzKq78nko71kJ/393m2MImvIoUN704wxN0+NneUJ8+4vVHMp9daTsddiQVVVSc4aNj/ZWru3p94uaEXWoqpOy+QLG+9orV2xo/EkGX8tvjuTQw+S5KmZHMM2HaDeVlWntdYuXfQs14+V+Nk4L8mTk5yQ5MaquiKTQ0OelOSoTPaKvLS1dtfSp8sSzK3XV1tr9ywwZtS/37vaHqq9h3bbjDFbh3afJdSbVXMp9daTsddilrck+eGh3tmdtXZFo69FVR2Y5Lcy+bbrG5Y/tXVn7LXYf97938nkm2THDK/zQ0kuTvKdSf64qg771qeve6P/bLTWtiU5KcmvJ9kzk2D1wkzC1L9kcjD0luVMliXZmX+Dkux6gYp1pqpenMmxOw8m+bnW2j+s8pTWi/dlcqqEn2+tfW21J7OO1bz7WzL5cszVrbWtrbVrkzwnyRcz2WvlHxs7QVUdlMleqFcneWMe2ov45EwC71uSXD4cUsIuZFcLVHO79facMWZud/jdS6g3q+ZS6q0nY6/Ft6iqU5N8YNh8WWvtI8upsw6MuhZV9ZJM/gX+ntbaZX1TW3dW8nfUBdMfd7fWvpnkvcPm8Yua4fqyEr+nPpjJXsI3tdbOaa3d0Frb1lq7KslPZvItwB9M8rrlTJhFW/G/QdN2tWOoNg3twTPGzPVtmjFmzo3z7h+SyQ9CT731ZNPQjrUW/5+qem4m39x4WJKXt9Y+sIOnrGebhnastZj7RswxVXXZVN+BQ3vUvL7TWmu3LqLuerBpaMdai02ZfO27kvzTAmPmHj9oEfXWm01DO8p6DN8a/LFh80PT/a21+6vqokzOnXd8JnurWBmbhna/qtp7geOoRv37vavtoZr76vz+VbXQQWZHD+01OyrWWrs7yT9OPW/Z9daZUddivqo6OckfZnJy1Ve01t6/vCmuGyu1FkcnefrU7fChb795jz1ySbPdtY39O2prJqesSBY+Xcjc41sX6F/Pxv7ZOGTe/YX2eswdjP6YBfoZx5cyOS9hspP+fu9Sgaq1tjnJVcPm6dP9VXVcJon03kwO1lyMj82ot1cmH30kyR8tabK7uBVai1TVSZmcrG23TMLUe3fwlHVv7LVorZ3cWqvt3ZL87DDsknmPbxrnnXz7W6Gfi7mPuhf6SG9uj8nnFllv3ViB9Zh/sPlTFhjz1KFd6DQNjKC1dl+SPxk2t7e2j09y7LD5sen+5b7oLnXLwpcR2D8LXEYgk48wrs/kj8B0vfmXnnnZvMcfnodOi+/SMztnLU7M5Bfbg5l3GSC3nb8WM17nZ+JM6Tt1LTLZA3XH8LyXT/Wdloeur3jiar/3tXhbgfWYO/P6/07yhKm+F81bjxet9ntf67cs4kzpSc4Y1uL3ttN3ZB669MyPz3vcpWeWsAhz11K6L5OTrF2Uhy50eXmmLnQ574/ApgXqnZqHLsB7ZSYfN7k48k5ciySPzeQMxC2Tc4dcMOM22sUud6Xb2D8XC7zG3HMEqp24Fpnshfr6MOaLmey1uiYPXVz2v6z2e17LtzHXI8n3J/m/Q//Xk/zFsB5fnLcevx//CN/eOhw5/I2du839d7yZ2B42AAABHUlEQVR56vGD5j3nPw9jLlug5vyLI/9FJheqnrv2q4sjL3JhXpDJlaXvyuRz1OuS/HKSR2xn7A7/cGRyDpGPJvlKJntJNiV5V5LHrfZ7Xeu3MdYik5OstkXenrDa73mt3sb+uZjxHIFqJ69FJmeGviDJ5kyCwe2ZfOTxrNV+r98OtzHXI8njkpyb5NpMjl27f/jb8ekkL1jt97pWb0n+3VJ/x2cHgWoYc3wmQflfMvmH+d8nOSfJ3mPOv4YXAwBgmXapg9IBAFaDQAUA0EmgAgDoJFABAHQSqAAAOglUAACdBCoAgE4CFQBAJ4EKAKCTQAUA0EmgAgDoJFABAHQSqAAAOglUAACdBCoAgE4CFQBAJ4EKAKCTQAUA0On/AS5zwPyxiKlJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plot\n",
    "plt.figure(figsize=(4, 3), dpi=160)\n",
    "plt.scatter(x[:, 0], x[:, 1], c=cluster_id_x, cmap='cool')\n",
    "plt.scatter(\n",
    "    cluster_centers[:, 0], cluster_centers[:, 1],\n",
    "    c='white',\n",
    "    alpha=0.6,\n",
    "    edgecolors='black',\n",
    "    linewidths=2\n",
    ")\n",
    "plt.axis([-1, 1, -1, 1])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.3874e-01,  7.0128e-01, -5.3805e-02, -4.0267e-01, -5.0856e-04,\n",
       "          2.9277e-01, -5.4196e-01,  3.1095e-01, -4.6652e-01, -1.1234e+00,\n",
       "          1.6283e-01,  1.7323e-01, -8.0080e-02,  3.7724e-01, -3.1270e-01,\n",
       "          2.7074e-01, -3.9440e-01, -1.8794e-01,  3.6960e-02, -2.9776e-01,\n",
       "          1.4233e-02,  1.0848e-01,  1.3028e-01,  6.9313e-02, -5.9848e-01,\n",
       "          1.9882e-01, -3.3160e-02,  9.3312e-01,  4.9680e-02, -8.0809e-02,\n",
       "         -4.1121e-01, -1.3642e-01, -2.9934e-02, -5.8748e-02, -1.3513e+00,\n",
       "          5.0210e-02,  6.0034e-01, -4.2593e-02,  1.7736e-02, -1.2450e-01,\n",
       "          2.9259e-01, -3.5067e-01, -4.7843e-01,  8.2427e-01, -2.0723e-01,\n",
       "         -8.5485e-02,  3.3813e-01, -9.2301e-02, -4.7457e-01,  1.9979e-01,\n",
       "         -1.7752e-01, -3.0613e-01, -2.5884e-01, -1.0282e-01, -3.0197e-01,\n",
       "          3.5154e-01, -3.9977e-01, -4.2541e-01, -2.4393e-01,  1.2961e-01,\n",
       "          4.5638e-01, -2.1603e-01, -5.4387e-03,  3.6337e-01, -2.1843e-01,\n",
       "         -5.6234e-01,  4.1026e-01,  3.0332e-02, -4.2877e-01,  5.7836e-02,\n",
       "          3.7405e-01,  5.2017e-01, -3.0871e-01, -5.1731e-01,  6.2518e-02,\n",
       "          4.3128e-01, -1.8547e-01, -2.6516e-01, -5.1891e-01, -2.2419e-01,\n",
       "         -3.8689e-02, -2.2170e-01, -4.7697e-01,  3.4949e-01,  5.6790e-01,\n",
       "          1.4519e-01, -1.0370e-01,  5.4611e-02, -3.3071e-01, -3.8481e-01,\n",
       "          5.1766e-02,  2.2034e-01, -6.2923e-02,  3.0185e-01, -3.2121e-01,\n",
       "          1.0314e-01, -7.0875e-01,  2.6722e-01,  1.7629e-01, -3.2700e-01,\n",
       "         -3.3967e-01,  1.8756e-01,  1.4735e-01, -2.5674e-01, -4.3240e-02,\n",
       "         -3.2177e-01, -4.0497e-01, -4.9942e-01, -5.5540e-01,  7.5864e-02,\n",
       "         -5.7523e-02, -4.6841e-04, -5.8727e-02, -3.6933e-01, -1.9738e-01,\n",
       "          7.5427e-01, -5.2081e-01, -5.6082e-02, -2.9409e-01, -5.5711e-01,\n",
       "          7.4640e-02, -1.8692e-01,  8.0940e-01, -1.1441e-01, -4.0021e-01,\n",
       "          6.6556e-02, -1.9320e-01,  1.9823e-01, -3.5245e-02,  3.5052e-01,\n",
       "          1.7019e-01,  3.4688e-01, -9.5130e-02,  1.9047e-03, -8.8518e-02,\n",
       "         -2.6366e-01, -2.1091e-01,  3.4483e-01,  2.4876e-01,  3.9238e-01,\n",
       "         -1.0449e-01, -4.7423e-02,  3.3625e-01, -1.3066e-01, -1.7352e-01,\n",
       "          2.5505e-01,  3.1466e-01, -3.7230e-01,  5.8019e-02, -8.9515e-02,\n",
       "          1.3338e+00,  3.2331e-03,  2.2157e-01, -7.4067e-02,  3.9075e-01,\n",
       "          1.3139e-01, -2.1024e-01, -1.0781e-01,  2.0957e-01,  3.8259e-01,\n",
       "          1.2990e-02,  6.3276e-02, -3.7347e-01,  2.8526e-01,  2.4801e-01,\n",
       "         -9.2949e-02, -1.0922e-01, -1.1339e-01, -9.1947e-02, -5.8546e-01,\n",
       "         -1.5367e-01, -3.1417e-02, -9.5565e-01, -7.6676e-01,  2.1306e-02,\n",
       "          3.2957e-01,  5.2976e-02,  1.3702e-01, -3.6736e-01,  6.3608e-01,\n",
       "          1.6121e-02, -1.5032e-01,  6.5054e-01, -1.5694e-01,  1.2998e-01,\n",
       "         -7.1072e-01, -8.9383e-02,  1.5450e-01, -4.2476e-01,  2.7277e-01,\n",
       "          6.5318e-01,  1.5698e-01, -1.0336e-02,  1.6955e-01,  5.1765e-01,\n",
       "         -6.4437e-02, -3.6354e-01,  9.1028e-02,  5.8696e-01,  1.0231e-01,\n",
       "          1.8188e+00, -1.4951e-01,  5.3356e-01, -2.3076e-01, -4.0910e-01,\n",
       "          2.6372e-01, -5.9218e-01, -2.2738e-01, -7.1998e-02, -4.2102e-01,\n",
       "          4.4052e-01, -3.0195e-01,  4.1657e-01,  5.8681e-02,  4.6086e-01,\n",
       "         -3.2788e-01, -5.3459e-01, -1.4957e-01,  5.3477e-01, -1.0169e-01,\n",
       "          2.4287e-01, -2.6991e-01,  7.7386e-02,  4.4239e-02,  3.8366e-02,\n",
       "          7.1475e-02, -3.2204e-01,  6.1681e-02, -6.0687e-02,  4.0871e-01,\n",
       "          1.8182e-02, -1.2235e-01,  7.2642e-01,  1.3879e-01,  7.2070e-01,\n",
       "         -1.0566e-01,  1.1182e-01,  1.6458e-01,  4.0663e-01, -7.4292e-02,\n",
       "         -4.4881e-02,  8.7292e-05,  4.3652e-01, -2.6724e-01,  1.4049e-02,\n",
       "          8.6399e-02,  4.8446e-01, -4.3232e-02, -4.0704e-03,  2.1296e-01,\n",
       "         -2.9449e-01, -4.4953e-01, -9.0638e-02, -2.9931e-01,  6.0006e-01,\n",
       "         -3.7418e-01,  1.3766e-01,  2.4943e-01, -5.9580e-01,  6.6206e-01,\n",
       "         -2.4554e-01, -1.3272e-02,  1.8078e-01, -3.2580e-01,  1.5115e-01,\n",
       "         -6.0811e-01, -1.3553e-01, -1.3603e-01,  2.9747e-01,  1.3512e-01,\n",
       "         -2.4197e-01, -2.4558e-01,  1.4265e-01,  3.7087e-01,  2.5794e-01,\n",
       "          5.0436e-01, -1.3602e+00, -4.8954e-01,  8.6180e-02, -5.7990e-01,\n",
       "          1.1513e-01, -2.6709e-01, -4.9999e-01,  3.6437e-01,  8.0430e-02,\n",
       "          4.2919e-02,  1.2798e-01,  1.2643e-01,  4.3423e-01, -6.2228e-02,\n",
       "         -3.2715e-01, -5.6580e-01, -2.8795e-01,  3.0503e-01,  2.1195e-01,\n",
       "          4.2207e-01,  1.5113e-01, -3.3109e-01, -4.2808e-01, -5.9559e-02,\n",
       "         -6.9081e-02,  4.4487e-02, -3.4491e-02,  2.1045e-01, -2.0927e-01,\n",
       "          4.6236e-02, -2.9651e-01, -3.3580e-01,  5.7832e-03,  1.9152e-02,\n",
       "         -1.1688e-01, -1.9023e-01,  8.5638e-03,  2.5381e-02,  2.3250e-01,\n",
       "          5.9002e-02,  8.7960e-02, -9.0075e-02, -1.4376e-01,  1.0444e-01,\n",
       "          7.5955e-02,  1.9220e-01,  1.4745e-01,  1.1123e-01,  7.4780e-02,\n",
       "          6.4681e-02, -5.7159e-02,  1.0440e-01,  6.3763e-03, -3.5075e-02,\n",
       "          3.0904e-01,  1.2653e-01, -4.4548e-02,  1.0224e-01,  2.3378e-01,\n",
       "         -9.2053e-02,  1.8009e-01, -1.7385e-01, -1.7260e-03,  3.1885e-02,\n",
       "          8.0266e-02, -2.2391e-01, -9.3329e-02, -1.0363e-01, -2.6481e-01,\n",
       "          1.2728e-01, -1.4514e-01,  2.7646e-01,  6.3080e-03,  7.4213e-02],\n",
       "        [-3.5020e-01,  5.7878e-01, -2.5017e-01,  5.8048e-02,  3.5620e-02,\n",
       "          5.0380e-01,  2.8435e-01,  2.8262e-02, -1.4925e-01, -1.2655e+00,\n",
       "          3.1383e-01,  1.4420e-01, -2.5478e-02, -2.7895e-02, -1.1468e-01,\n",
       "          1.2612e-02, -4.6635e-01, -4.4645e-01, -4.2851e-01, -1.1794e-01,\n",
       "          9.1640e-02, -1.8313e-01, -1.3727e-01,  2.2871e-01, -1.8703e-01,\n",
       "          2.9337e-01,  2.6247e-01,  6.3634e-01,  1.9273e-01,  4.6383e-01,\n",
       "          2.5579e-01, -2.0361e-01, -4.4360e-01, -1.1775e-01, -8.3568e-01,\n",
       "         -2.7975e-01,  2.7284e-02,  2.4812e-01,  1.8964e-01, -2.7591e-02,\n",
       "         -5.3523e-02,  2.5216e-01, -2.6300e-01,  1.9716e-01,  5.1143e-02,\n",
       "          4.9007e-01, -3.8253e-02,  3.4514e-01, -2.9330e-01, -3.6695e-03,\n",
       "          2.5752e-02,  1.0500e-01, -1.8418e-01, -5.0901e-01, -1.3572e-01,\n",
       "          7.2688e-01, -2.3528e-01, -1.1466e-01, -1.7038e-01,  3.7100e-01,\n",
       "          2.4301e-01, -6.5612e-01,  9.4547e-02, -1.4623e-01, -1.2989e-01,\n",
       "         -8.0629e-02, -7.6466e-02,  4.3545e-01, -1.8195e-01,  1.2406e-01,\n",
       "          5.1307e-01, -4.3708e-02, -2.2771e-01, -1.4780e-01,  1.5377e-01,\n",
       "         -2.3050e-01, -3.5367e-01, -3.7916e-01,  1.3743e-01,  2.9376e-02,\n",
       "         -3.6976e-02, -2.1662e-01, -2.6740e-01,  4.8782e-03, -3.6648e-01,\n",
       "          2.9608e-01, -5.1210e-03, -8.4541e-02, -7.8453e-02,  1.1844e-01,\n",
       "         -9.1809e-02, -1.4622e-01, -2.6025e-01, -2.3868e-01,  3.0888e-02,\n",
       "         -2.9102e-01, -5.0207e-01,  3.6413e-01,  1.2695e-01, -5.2500e-01,\n",
       "          1.1804e-01,  1.3148e-01, -4.6549e-01, -2.9881e-01,  3.1374e-01,\n",
       "          1.2703e-01,  6.4562e-01, -2.8254e-01,  5.1173e-01,  2.2212e-02,\n",
       "         -1.3133e-01, -2.1787e-01, -5.4813e-02, -4.3257e-01, -1.1565e-01,\n",
       "         -6.2924e-01, -1.0403e-01, -1.5005e-01,  2.5123e-01,  5.1192e-01,\n",
       "         -1.7415e-01, -4.3658e-01,  1.9793e-01,  2.1308e-01, -1.5695e-01,\n",
       "          3.4315e-01,  8.8164e-01,  7.0501e-01,  5.9003e-01,  1.2878e-01,\n",
       "          2.6968e-01,  1.8804e-01,  3.2173e-01,  4.0927e-01, -2.1554e-01,\n",
       "         -1.4002e-01,  1.6018e-01,  3.1689e-01,  1.8012e-01, -1.1951e-01,\n",
       "         -4.6807e-01, -3.8040e-01,  1.6797e-01,  3.7634e-01, -9.9550e-01,\n",
       "          6.0323e-03, -2.1219e-01, -1.5493e-01, -3.3203e-01, -1.8968e-01,\n",
       "          4.1704e-01,  1.1240e-02,  1.4821e-01, -2.1417e-01,  4.8669e-01,\n",
       "          4.0356e-01, -4.2542e-01, -2.5642e-01, -6.9874e-01, -1.1534e-01,\n",
       "         -3.1356e-01, -2.1189e-01,  2.7463e-01, -2.2154e-01,  1.3182e-01,\n",
       "         -3.6775e-01, -1.5459e-01, -2.2086e-01, -3.0432e-01,  1.5835e-01,\n",
       "         -3.5481e-01,  4.5469e-01, -4.7405e-02, -1.6408e-02, -2.0956e-01,\n",
       "          8.9672e-02,  4.5965e-02,  1.9498e-01, -3.4699e-01,  4.2865e-01,\n",
       "          5.0651e-01, -3.5229e-01, -4.7414e-02,  1.2609e-01, -1.1103e-02,\n",
       "          2.8337e-02, -1.8455e-01,  2.3862e-01,  8.0975e-02,  4.0918e-01,\n",
       "         -2.5137e-02,  5.9014e-01,  4.9563e-01, -1.0193e-01,  2.6996e-01,\n",
       "         -2.9393e-01,  2.7789e-01,  4.6911e-01,  2.2892e-01,  4.0751e-03,\n",
       "          1.3514e+00, -2.6998e-02,  3.8141e-01,  7.5012e-03, -5.3611e-01,\n",
       "          4.3388e-02, -1.2428e-01, -1.1850e-01,  1.7287e-01, -8.1948e-02,\n",
       "         -4.3919e-01, -1.1482e-01,  1.0087e-01,  4.0947e-01,  7.0324e-02,\n",
       "         -2.6824e-01,  8.9544e-02,  5.7645e-01,  2.0290e-01, -2.6760e-01,\n",
       "          7.9614e-01, -4.2393e-01, -2.6491e-01, -2.0554e-01, -4.6100e-01,\n",
       "          3.9907e-02, -1.7195e-02, -8.1654e-02, -2.1088e-01, -6.5610e-02,\n",
       "         -3.6282e-02,  6.1349e-01, -3.1551e-03,  1.9350e-01,  8.4085e-02,\n",
       "          4.5196e-02, -3.1515e-01,  6.4512e-01, -1.6919e-02, -2.8829e-01,\n",
       "         -3.6882e-01,  2.2288e-01,  1.5899e-01, -8.6200e-02, -3.6832e-01,\n",
       "          9.8550e-02,  2.5698e-01,  1.8479e-01, -2.3339e-01,  1.5676e-01,\n",
       "         -3.2647e-01, -3.2121e-02, -2.1072e-01, -5.3687e-01, -3.7762e-01,\n",
       "         -2.5392e-01,  4.5003e-02,  2.3364e-01, -1.9944e-02,  5.8805e-01,\n",
       "          6.9525e-01, -3.7580e-01,  1.2846e-01, -3.9452e-01, -4.1482e-01,\n",
       "          2.4874e-01,  1.9678e-01, -2.3605e-01,  1.3205e-01,  1.9523e-02,\n",
       "         -1.4852e-01,  3.2267e-02,  3.5885e-01, -1.0694e-01,  1.8976e-01,\n",
       "         -2.3182e-01, -1.5124e+00, -2.4568e-02,  5.3008e-01, -2.6194e-01,\n",
       "          2.4928e-01,  9.1654e-02, -3.7952e-03, -3.3254e-02, -3.9683e-01,\n",
       "         -1.3434e-01,  3.0003e-01, -1.4897e-01, -1.6900e-01,  7.1563e-01,\n",
       "         -4.2242e-01, -4.6801e-01,  3.7033e-01,  5.7892e-03,  4.4254e-01,\n",
       "          5.4729e-01, -6.6444e-02, -1.2046e-01, -1.7165e-01, -2.5292e-02,\n",
       "         -5.7236e-02,  1.2857e-01,  7.0633e-02,  8.7674e-02, -1.4226e-01,\n",
       "         -1.5879e-01, -2.0343e-01, -3.4695e-01, -1.5237e-02,  4.4076e-02,\n",
       "         -1.5241e-01, -2.2940e-01,  1.0939e-01,  1.0296e-01,  2.2304e-01,\n",
       "          9.5153e-02,  7.1791e-02, -8.8282e-02,  4.9418e-03,  5.6633e-02,\n",
       "          8.4881e-02,  1.6225e-01,  1.0889e-01,  1.2810e-01, -1.0163e-01,\n",
       "          2.9012e-02, -9.0812e-02,  1.1191e-01,  5.3235e-02, -5.6833e-02,\n",
       "         -5.3015e-02, -5.9873e-03, -4.5350e-02,  1.6402e-01, -7.2347e-03,\n",
       "         -4.9187e-02,  2.7950e-01, -2.5652e-02, -5.3745e-02,  1.4520e-01,\n",
       "          1.8542e-01, -8.3542e-02,  1.9346e-02, -1.3422e-01, -1.6804e-01,\n",
       "          1.3442e-01, -9.3196e-02,  1.6047e-01,  7.3343e-02,  1.0679e-01]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([all_entity_mentions_span_rep[0],all_entity_mentions_span_rep[1]],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_entity_mentions_span_rep_stack = torch.stack(all_entity_mentions_span_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1387,  0.7013, -0.0538,  ...,  0.2765,  0.0063,  0.0742],\n",
       "        [-0.3502,  0.5788, -0.2502,  ...,  0.1605,  0.0733,  0.1068],\n",
       "        [ 0.1170,  0.9497,  0.0987,  ...,  0.2387,  0.0813,  0.1165],\n",
       "        ...,\n",
       "        [-0.0763, -0.1478, -0.3952,  ...,  0.1580,  0.1285,  0.1561],\n",
       "        [-0.1733,  0.0333,  0.0802,  ...,  0.1965,  0.1108,  0.1529],\n",
       "        [-0.2413,  0.1513,  0.0168,  ...,  0.1687,  0.1128,  0.1364]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_entity_mentions_span_rep_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
